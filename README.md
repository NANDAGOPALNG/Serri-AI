# ğŸ¤– AI Customer Support Bot with Document Training & Feedback Loop

An intelligent customer support chatbot that learns from FAQ documents, answers queries using NLP models, and iteratively improves responses through simulated feedback mechanisms.

[![Live Demo](https://img.shields.io/badge/ğŸ¤—%20Hugging%20Face-Live%20Demo-blue)](https://huggingface.co/spaces/NG-2004/Serri)
[![Python](https://img.shields.io/badge/Python-3.8+-green.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸŒŸ Live Demo

Try the bot now: **[https://huggingface.co/spaces/NG-2004/Serri](https://huggingface.co/spaces/NG-2004/Serri)**

## ğŸ“‹ Overview

This project implements an agentic workflow that:
- Trains on provided documents (FAQ, manuals, policies)
- Uses semantic search to find relevant information
- Generates accurate answers using transformer-based Q&A models
- Improves responses through a feedback loop (max 2 iterations)
- Logs all decisions and actions for transparency
- Handles out-of-scope queries gracefully

## âœ¨ Features

- **ğŸ“„ Document Training**: Ingests and processes FAQ documents
- **ğŸ§  Semantic Search**: Uses sentence embeddings for intelligent context retrieval
- **ğŸ’¬ Question Answering**: Employs DistilBERT for extractive Q&A
- **ğŸ”„ Feedback Loop**: Simulates user feedback and adjusts responses accordingly
- **ğŸ“ Comprehensive Logging**: Tracks all queries, decisions, and iterations
- **ğŸŒ Gradio Interface**: Interactive web UI with multiple tabs
- **ğŸš€ HuggingFace Deployment**: Deployed on free CPU tier

## ğŸ› ï¸ Technology Stack

- **Python 3.8+**
- **Transformers** (Hugging Face) - Question answering
- **Sentence Transformers** - Semantic search and embeddings
- **PyTorch** - Deep learning backend
- **Gradio** - Web interface
- **Logging** - Decision tracking

## ğŸ”§ Installation

### Local Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/customer-support-bot.git
cd customer-support-bot

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Requirements

```txt
transformers==4.35.0
sentence-transformers==2.2.2
torch==2.1.0
gradio==4.8.0
```

## ğŸš€ Usage

### Run Jupyter Notebook

```bash
jupyter notebook Support_bot.ipynb
```

### Run as Python Script

Create `app.py` from the notebook cells and run:

```bash
python app.py
```

The Gradio interface will launch at `http://127.0.0.1:7860`

## ğŸ“‚ Project Structure

```
customer-support-bot/
â”œâ”€â”€ Support_bot.ipynb          # Main development notebook
â”œâ”€â”€ faq.txt                    # Sample FAQ document
â”œâ”€â”€ support_bot_log.txt        # Generated log file
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # This file
â””â”€â”€ app.py                     # Standalone Python script (optional)
```

## ğŸ¯ How It Works

### 1. Document Processing
- Loads FAQ document and splits into sections
- Creates vector embeddings for each section using `all-MiniLM-L6-v2`

### 2. Query Handling
- User submits a question
- Semantic search finds the most relevant section (cosine similarity)
- Relevance threshold: 0.3 (configurable)

### 3. Answer Generation
- Uses `distilbert-base-uncased-distilled-squad` for extractive Q&A
- Extracts answer from relevant context
- Returns confidence score

### 4. Feedback Loop
- Simulates user feedback: "good", "too vague", "not helpful"
- **Too vague** â†’ Adds more context from document
- **Not helpful** â†’ Rephrases query and retries
- **Good** â†’ Accepts response
- Maximum 2 iterations per query

### 5. Logging
All actions logged to `support_bot_log.txt`:
- Query received
- Relevant section found (with similarity score)
- Generated answer (with confidence)
- Feedback received
- Adjustments made

## ğŸ“Š Example Queries

```python
queries = [
    "How do I reset my password?",
    "What is your refund policy?",
    "How can I contact support?",
    "What are the shipping options?",
    "How do I track my order?",
    "What payment methods do you accept?"
]
```

## ğŸ¨ Gradio Interface

The web interface includes three tabs:

1. **ğŸ’¬ Chat**: Direct question answering
2. **ğŸ”„ Feedback Simulation**: Shows iterative improvement process
3. **ğŸ“Š About**: Information about the bot and technology

## ğŸ“ˆ Model Performance

| Model | Purpose | Size | Speed |
|-------|---------|------|-------|
| DistilBERT | Question Answering | ~250MB | Fast |
| MiniLM-L6-v2 | Sentence Embeddings | ~80MB | Very Fast |

## ğŸ”® Future Enhancements

### Planned Improvements

1. **ğŸ¦™ LLaMA 2 Integration**
   - Replace DistilBERT with LLaMA 2 for generative responses
   - Enable multi-turn conversations
   - Better context understanding
   - More natural, detailed answers

2. **ğŸ¤– GPT-2 Alternative**
   - Lightweight generative model option
   - Creative response generation
   - Abstractive summarization
   - Paraphrasing capabilities

3. **Additional Features**
   - Multi-document support
   - Real user feedback integration
   - Conversation history tracking
   - Fine-tuning on domain-specific data
   - Multi-language support
   - Confidence threshold tuning
   - RAG (Retrieval-Augmented Generation) pipeline
   - Vector database integration (Pinecone, Weaviate)

## ğŸ› Known Issues

- First run downloads models (~500MB) - takes 2-3 minutes
- CPU inference is slower than GPU
- Limited to extractive answers (no generation)
- Fixed relevance threshold (0.3)

## ğŸ“ Development Decisions

### Why DistilBERT?
- Lightweight (40% smaller than BERT)
- Fast inference on CPU
- Good accuracy for Q&A tasks
- Well-documented and supported

### Why Sentence Transformers?
- Semantic search outperforms keyword matching
- Handles paraphrased questions effectively
- Fast embedding generation
- Easy to use and deploy

### Why Gradio?
- Quick prototyping
- No web development required
- Built-in sharing capabilities
- Clean, modern UI

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

**Nanda Gopal**

- HuggingFace: [@NG-2004](https://huggingface.co/NG-2004)
- GitHub: [@NANDAGOPALNG](https://github.com/NANDAGOPALNG)

## ğŸ™ Acknowledgments

- Assignment provided by Serri AI
- Built with Hugging Face Transformers
- Deployed on Hugging Face Spaces
- Inspired by modern customer support systems

## ğŸ“§ Contact

For questions or support, please contact:
- Email: nandagopalng@gmail.com
- HuggingFace Space: [Live Demo](https://huggingface.co/spaces/NG-2004/Serri)

---

**Note**: This is a demonstration project for educational purposes. For production use, consider implementing proper authentication, rate limiting, and error handling.

## ğŸ“ Assignment Context

This project was developed as part of an ML internship assignment requiring:
- Document-based training
- NLP model integration
- Feedback loop implementation
- Logging and transparency
- Graceful error handling
- Interactive deployment

All requirements have been successfully implemented and deployed.
